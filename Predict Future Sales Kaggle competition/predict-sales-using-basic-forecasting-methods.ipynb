{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T11:20:19.517321Z","iopub.execute_input":"2022-05-24T11:20:19.517647Z","iopub.status.idle":"2022-05-24T11:20:19.543881Z","shell.execute_reply.started":"2022-05-24T11:20:19.517582Z","shell.execute_reply":"2022-05-24T11:20:19.543484Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Reading Inputs","metadata":{}},{"cell_type":"code","source":"#reading Inputs\nitems_df=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\n#items_df\nitems_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:20:19.545001Z","iopub.execute_input":"2022-05-24T11:20:19.545194Z","iopub.status.idle":"2022-05-24T11:20:19.644876Z","shell.execute_reply.started":"2022-05-24T11:20:19.545168Z","shell.execute_reply":"2022-05-24T11:20:19.644358Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"item_categories_df=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops_df=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:01.165035Z","iopub.execute_input":"2022-05-24T11:23:01.165307Z","iopub.status.idle":"2022-05-24T11:23:01.183131Z","shell.execute_reply.started":"2022-05-24T11:23:01.165277Z","shell.execute_reply":"2022-05-24T11:23:01.182665Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sales_train_df=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nsales_train_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:10.381220Z","iopub.execute_input":"2022-05-24T11:23:10.381512Z","iopub.status.idle":"2022-05-24T11:23:11.443941Z","shell.execute_reply.started":"2022-05-24T11:23:10.381484Z","shell.execute_reply":"2022-05-24T11:23:11.443189Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"#distribution of item ID\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6,5))\nplt.hist(sales_train_df['item_id'])\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:16.267464Z","iopub.execute_input":"2022-05-24T11:23:16.267835Z","iopub.status.idle":"2022-05-24T11:23:16.456837Z","shell.execute_reply.started":"2022-05-24T11:23:16.267802Z","shell.execute_reply":"2022-05-24T11:23:16.456252Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sales_train_df.groupby(['item_id']).nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:19.925210Z","iopub.execute_input":"2022-05-24T11:23:19.925529Z","iopub.status.idle":"2022-05-24T11:23:22.209376Z","shell.execute_reply.started":"2022-05-24T11:23:19.925500Z","shell.execute_reply":"2022-05-24T11:23:22.208713Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"There are 21807 unique items","metadata":{}},{"cell_type":"code","source":"sales_train_df[['shop_id','item_id','item_price','item_cnt_day']].corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:30.671408Z","iopub.execute_input":"2022-05-24T11:23:30.671789Z","iopub.status.idle":"2022-05-24T11:23:30.842102Z","shell.execute_reply.started":"2022-05-24T11:23:30.671754Z","shell.execute_reply":"2022-05-24T11:23:30.840898Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"No significant correlation between any 2 columns!","metadata":{}},{"cell_type":"code","source":"#EDA on train data\nsales_train_df.groupby(['shop_id']).nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:34.080870Z","iopub.execute_input":"2022-05-24T11:23:34.081089Z","iopub.status.idle":"2022-05-24T11:23:35.826167Z","shell.execute_reply.started":"2022-05-24T11:23:34.081066Z","shell.execute_reply":"2022-05-24T11:23:35.825382Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Distribution of shop_id\nplt.figure(figsize=(6,5))\nplt.hist(sales_train_df['shop_id'])\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:36.992843Z","iopub.execute_input":"2022-05-24T11:23:36.993556Z","iopub.status.idle":"2022-05-24T11:23:37.309203Z","shell.execute_reply.started":"2022-05-24T11:23:36.993520Z","shell.execute_reply":"2022-05-24T11:23:37.308478Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"There are 59 unique shops","metadata":{}},{"cell_type":"code","source":"#Getting total sales of a shop for a unique date\nsales_train_df.groupby(['shop_id','date_block_num']).sum('item_cnt_day')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:40.551869Z","iopub.execute_input":"2022-05-24T11:23:40.552110Z","iopub.status.idle":"2022-05-24T11:23:40.752989Z","shell.execute_reply.started":"2022-05-24T11:23:40.552081Z","shell.execute_reply":"2022-05-24T11:23:40.752482Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Getting total sales of a shop for a unique item and date\n#Transforming sales training set to required format as test.csv\nsales_train_df_groupby=sales_train_df.groupby(['shop_id','item_id','date_block_num'])['item_cnt_day'].sum().reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:48.798132Z","iopub.execute_input":"2022-05-24T11:23:48.798862Z","iopub.status.idle":"2022-05-24T11:23:49.441822Z","shell.execute_reply.started":"2022-05-24T11:23:48.798828Z","shell.execute_reply":"2022-05-24T11:23:49.441094Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sales_train_df_groupby","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:51.096679Z","iopub.execute_input":"2022-05-24T11:23:51.096993Z","iopub.status.idle":"2022-05-24T11:23:51.109129Z","shell.execute_reply.started":"2022-05-24T11:23:51.096970Z","shell.execute_reply":"2022-05-24T11:23:51.108122Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Inputs of Test.csv:shop_id,item_id** . \n**Output of Test.csv: item_cnt**. \n\nWe'll use \"sales_train_df_groupby\" for training the model. We shall split this into train and validation set to test the model accuracy. Right now, i'm thinking of using a multi-linear or decision tree based regressor. We shall tets the model RMSE and the aim is to get score as close to 1.00 .  ","metadata":{}},{"cell_type":"markdown","source":"## Linear Regression for Sales Prediction","metadata":{}},{"cell_type":"code","source":"#importing needed packages\nimport matplotlib.pyplot as plt  # To visualize\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:54.780634Z","iopub.execute_input":"2022-05-24T11:23:54.780847Z","iopub.status.idle":"2022-05-24T11:23:55.807763Z","shell.execute_reply.started":"2022-05-24T11:23:54.780826Z","shell.execute_reply":"2022-05-24T11:23:55.806634Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Getting X and Y variables\nX = sales_train_df_groupby.drop(columns=['item_cnt_day','date_block_num'])#['date_block_num','shop_id']  # values converts it into a numpy array\nY = sales_train_df_groupby['item_cnt_day']  # -1 means that calculate the dimension of rows, but have 1 column","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:23:57.887456Z","iopub.execute_input":"2022-05-24T11:23:57.887727Z","iopub.status.idle":"2022-05-24T11:23:57.907654Z","shell.execute_reply.started":"2022-05-24T11:23:57.887695Z","shell.execute_reply":"2022-05-24T11:23:57.906750Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\nX_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:00.551163Z","iopub.execute_input":"2022-05-24T11:24:00.551391Z","iopub.status.idle":"2022-05-24T11:24:01.136925Z","shell.execute_reply.started":"2022-05-24T11:24:00.551368Z","shell.execute_reply":"2022-05-24T11:24:01.135888Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Training and predicting for validation dataset\nlinear_regressor = LinearRegression()  # create object for the class\nlinear_regressor.fit(X_train, y_train)  # perform linear regression\nY_pred = linear_regressor.predict(X_test)  # make predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:18.560089Z","iopub.execute_input":"2022-05-24T11:24:18.560381Z","iopub.status.idle":"2022-05-24T11:24:18.697923Z","shell.execute_reply.started":"2022-05-24T11:24:18.560343Z","shell.execute_reply":"2022-05-24T11:24:18.696936Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, Y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, Y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, Y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:21.160516Z","iopub.execute_input":"2022-05-24T11:24:21.160802Z","iopub.status.idle":"2022-05-24T11:24:21.173226Z","shell.execute_reply.started":"2022-05-24T11:24:21.160773Z","shell.execute_reply":"2022-05-24T11:24:21.172594Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"RMSE is 7.5 which means model is having much deviation from the actual sale value. So, let's try Random forest regressor and xgboost techniques to predict sales value.","metadata":{}},{"cell_type":"markdown","source":"## **XGBoost Model**","metadata":{}},{"cell_type":"code","source":"item_cat_joined_df=items_df.merge(item_categories_df, on='item_category_id')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:34.550077Z","iopub.execute_input":"2022-05-24T11:24:34.550315Z","iopub.status.idle":"2022-05-24T11:24:34.564554Z","shell.execute_reply.started":"2022-05-24T11:24:34.550291Z","shell.execute_reply":"2022-05-24T11:24:34.563950Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sales_train_df_groupby_cat_join=sales_train_df_groupby.merge(item_cat_joined_df, on='item_id')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:37.179799Z","iopub.execute_input":"2022-05-24T11:24:37.180210Z","iopub.status.idle":"2022-05-24T11:24:37.439578Z","shell.execute_reply.started":"2022-05-24T11:24:37.180178Z","shell.execute_reply":"2022-05-24T11:24:37.439040Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sales_train_df_groupby_cat_join","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"Xgboost_X_train=sales_train_df_groupby_cat_join[['date_block_num','shop_id','item_id','item_category_id']]\nXgboost_X_train","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:45.429113Z","iopub.execute_input":"2022-05-24T11:24:45.429778Z","iopub.status.idle":"2022-05-24T11:24:45.513988Z","shell.execute_reply.started":"2022-05-24T11:24:45.429732Z","shell.execute_reply":"2022-05-24T11:24:45.513455Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"Xgboost_Y_train=sales_train_df_groupby_cat_join[['item_cnt_day']]\nXgboost_Y_train","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:48.667969Z","iopub.execute_input":"2022-05-24T11:24:48.668751Z","iopub.status.idle":"2022-05-24T11:24:48.686049Z","shell.execute_reply.started":"2022-05-24T11:24:48.668706Z","shell.execute_reply":"2022-05-24T11:24:48.684998Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nX_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(Xgboost_X_train, Xgboost_Y_train, test_size=0.2, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:52.123441Z","iopub.execute_input":"2022-05-24T11:24:52.124066Z","iopub.status.idle":"2022-05-24T11:24:52.782057Z","shell.execute_reply.started":"2022-05-24T11:24:52.124026Z","shell.execute_reply":"2022-05-24T11:24:52.781225Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"xg_reg = xgb.XGBRegressor(objective ='reg:linear',max_depth = 10,  n_estimators = 100)\nxg_reg.fit(X_train_xgb,y_train_xgb)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:54.280703Z","iopub.execute_input":"2022-05-24T11:24:54.280929Z","iopub.status.idle":"2022-05-24T11:26:06.224483Z","shell.execute_reply.started":"2022-05-24T11:24:54.280907Z","shell.execute_reply":"2022-05-24T11:26:06.223600Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"preds = xg_reg.predict(X_test_xgb)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:26:06.225856Z","iopub.execute_input":"2022-05-24T11:26:06.226069Z","iopub.status.idle":"2022-05-24T11:26:06.882626Z","shell.execute_reply.started":"2022-05-24T11:26:06.226041Z","shell.execute_reply":"2022-05-24T11:26:06.882032Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_test_xgb, preds))\nprint(\"RMSE: %f\" % (rmse))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:26:06.886318Z","iopub.execute_input":"2022-05-24T11:26:06.888404Z","iopub.status.idle":"2022-05-24T11:26:06.898814Z","shell.execute_reply.started":"2022-05-24T11:26:06.888365Z","shell.execute_reply":"2022-05-24T11:26:06.897751Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"By using XGBoost, Now RMSE has further reduced to 4.68 from Linear regression's 7.65. So, XGBoost is much more efficient predicting sales price compared to Linear regression.\n\nNow let's try using Random Forest regressor,Deep learning methods and Time series for much better accuracy.","metadata":{}},{"cell_type":"markdown","source":"## **Random Forest Regressor to predict sales**","metadata":{}},{"cell_type":"code","source":"#Random forest regressor model building\nfrom sklearn.ensemble import RandomForestRegressor\nX_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(Xgboost_X_train, Xgboost_Y_train, test_size=0.2, random_state=123)\nRF_model = RandomForestRegressor()\nRF_model.fit(X_train_rf, y_train_rf)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:27:03.301705Z","iopub.execute_input":"2022-05-24T11:27:03.301947Z","iopub.status.idle":"2022-05-24T11:34:03.305382Z","shell.execute_reply.started":"2022-05-24T11:27:03.301917Z","shell.execute_reply":"2022-05-24T11:34:03.304257Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"RF_pred=RF_model.predict(X_test_rf)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:34:03.307329Z","iopub.execute_input":"2022-05-24T11:34:03.307652Z","iopub.status.idle":"2022-05-24T11:34:24.067168Z","shell.execute_reply.started":"2022-05-24T11:34:03.307607Z","shell.execute_reply":"2022-05-24T11:34:24.066402Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"rmse_rf = np.sqrt(mean_squared_error(y_test_rf, RF_pred))\nprint(\"RMSE: %f\" % (rmse))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:34:24.067947Z","iopub.execute_input":"2022-05-24T11:34:24.068097Z","iopub.status.idle":"2022-05-24T11:34:24.075579Z","shell.execute_reply.started":"2022-05-24T11:34:24.068077Z","shell.execute_reply":"2022-05-24T11:34:24.074496Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Random forest and XGBoost are almost having same error predicting.","metadata":{}},{"cell_type":"markdown","source":"## **Time Series Analysis**","metadata":{}},{"cell_type":"code","source":"ts=sales_train_df.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:34:24.077378Z","iopub.execute_input":"2022-05-24T11:34:24.077610Z","iopub.status.idle":"2022-05-24T11:34:24.292208Z","shell.execute_reply.started":"2022-05-24T11:34:24.077586Z","shell.execute_reply":"2022-05-24T11:34:24.291367Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(ts.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:34:24.293552Z","iopub.execute_input":"2022-05-24T11:34:24.293752Z","iopub.status.idle":"2022-05-24T11:34:24.451671Z","shell.execute_reply.started":"2022-05-24T11:34:24.293728Z","shell.execute_reply":"2022-05-24T11:34:24.450917Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**Quick observations:** There is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a decreasing \"Trend\".\n\nLet's check that with a quick decomposition into Trend, seasonality and residuals.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n# multiplicative\nres = sm.tsa.seasonal_decompose(ts.values,period=12,model=\"multiplicative\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:34:24.452617Z","iopub.execute_input":"2022-05-24T11:34:24.452787Z","iopub.status.idle":"2022-05-24T11:34:25.733673Z","shell.execute_reply.started":"2022-05-24T11:34:24.452764Z","shell.execute_reply":"2022-05-24T11:34:25.732804Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Additive model\nres = sm.tsa.seasonal_decompose(ts.values,period=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:26.434848Z","iopub.execute_input":"2022-05-24T11:35:26.435062Z","iopub.status.idle":"2022-05-24T11:35:26.797157Z","shell.execute_reply.started":"2022-05-24T11:35:26.435039Z","shell.execute_reply":"2022-05-24T11:35:26.796613Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"There is seasonality and residual plot is not random and seems to follow a pattern. Lets check if series is non-stationary. We shall do ADF stationarity test.","metadata":{}},{"cell_type":"code","source":"# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:30.657585Z","iopub.execute_input":"2022-05-24T11:35:30.658330Z","iopub.status.idle":"2022-05-24T11:35:30.664017Z","shell.execute_reply.started":"2022-05-24T11:35:30.658294Z","shell.execute_reply":"2022-05-24T11:35:30.663576Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(ts)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:33.878831Z","iopub.execute_input":"2022-05-24T11:35:33.879648Z","iopub.status.idle":"2022-05-24T11:35:33.905543Z","shell.execute_reply.started":"2022-05-24T11:35:33.879598Z","shell.execute_reply":"2022-05-24T11:35:33.904884Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"##### our p-value for the DF test is well within 5 %. Hence we can assume Stationarity of the series.","metadata":{}},{"cell_type":"markdown","source":"### ARMA models:","metadata":{}},{"cell_type":"markdown","source":"MA - Next value in the series is a function of the average of the previous n number of values AR - The errors(difference in mean) of the next value is a function of the errors in the previous n number of values ARMA - a mixture of both.\n\nNow, How do we find out, if our time-series in AR process or MA process?\n\nLet's find out!","metadata":{}},{"cell_type":"code","source":"def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:38.066162Z","iopub.execute_input":"2022-05-24T11:35:38.066546Z","iopub.status.idle":"2022-05-24T11:35:38.075714Z","shell.execute_reply.started":"2022-05-24T11:35:38.066508Z","shell.execute_reply":"2022-05-24T11:35:38.074631Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")\n\n##From the graph it's visible that ACF tails out and PACF cuts at lag1","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:41.712576Z","iopub.execute_input":"2022-05-24T11:35:41.712834Z","iopub.status.idle":"2022-05-24T11:35:42.307072Z","shell.execute_reply.started":"2022-05-24T11:35:41.712806Z","shell.execute_reply":"2022-05-24T11:35:42.306395Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Simulate an AR(2) process\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:46.361355Z","iopub.execute_input":"2022-05-24T11:35:46.362277Z","iopub.status.idle":"2022-05-24T11:35:46.941496Z","shell.execute_reply.started":"2022-05-24T11:35:46.362220Z","shell.execute_reply":"2022-05-24T11:35:46.940506Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Simulate an MA(1) process\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T13:14:50.15781Z","iopub.execute_input":"2022-05-22T13:14:50.158119Z","iopub.status.idle":"2022-05-22T13:14:50.948185Z","shell.execute_reply.started":"2022-05-22T13:14:50.158087Z","shell.execute_reply":"2022-05-22T13:14:50.947113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simulate an ARMA(2, 2) model with alphas=[0.5,-0.25] and betas=[0.5,-0.3]\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:35:49.004954Z","iopub.execute_input":"2022-05-24T11:35:49.006000Z","iopub.status.idle":"2022-05-24T11:35:49.704646Z","shell.execute_reply.started":"2022-05-24T11:35:49.005949Z","shell.execute_reply":"2022-05-24T11:35:49.703720Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## **DEEP LEARNING METHOD**","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom tensorflow import keras\nimport tensorflow as tf\n\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:06.809131Z","iopub.execute_input":"2022-05-24T11:36:06.809370Z","iopub.status.idle":"2022-05-24T11:36:13.075375Z","shell.execute_reply.started":"2022-05-24T11:36:06.809339Z","shell.execute_reply":"2022-05-24T11:36:13.074658Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler,StandardScaler\n\nsc = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:21.201656Z","iopub.execute_input":"2022-05-24T11:36:21.201959Z","iopub.status.idle":"2022-05-24T11:36:21.206890Z","shell.execute_reply.started":"2022-05-24T11:36:21.201930Z","shell.execute_reply":"2022-05-24T11:36:21.205972Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"dataset=[]\ndataset = sales_train_df.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:23.215105Z","iopub.execute_input":"2022-05-24T11:36:23.215564Z","iopub.status.idle":"2022-05-24T11:36:26.231365Z","shell.execute_reply.started":"2022-05-24T11:36:23.215534Z","shell.execute_reply":"2022-05-24T11:36:26.230570Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:26.232744Z","iopub.execute_input":"2022-05-24T11:36:26.233070Z","iopub.status.idle":"2022-05-24T11:36:26.340564Z","shell.execute_reply.started":"2022-05-24T11:36:26.233031Z","shell.execute_reply":"2022-05-24T11:36:26.339587Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"dataset.reset_index(inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:29.535607Z","iopub.execute_input":"2022-05-24T11:36:29.535920Z","iopub.status.idle":"2022-05-24T11:36:29.547571Z","shell.execute_reply.started":"2022-05-24T11:36:29.535884Z","shell.execute_reply":"2022-05-24T11:36:29.546645Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"dataset = pd.merge(test_df,dataset,on = ['item_id','shop_id'],how = 'left')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:31.785267Z","iopub.execute_input":"2022-05-24T11:36:31.785573Z","iopub.status.idle":"2022-05-24T11:36:32.027597Z","shell.execute_reply.started":"2022-05-24T11:36:31.785542Z","shell.execute_reply":"2022-05-24T11:36:32.026846Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"dataset.fillna(0,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:41.240475Z","iopub.execute_input":"2022-05-24T11:36:41.241033Z","iopub.status.idle":"2022-05-24T11:36:41.280195Z","shell.execute_reply.started":"2022-05-24T11:36:41.240977Z","shell.execute_reply":"2022-05-24T11:36:41.279509Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"dataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:43.509033Z","iopub.execute_input":"2022-05-24T11:36:43.509756Z","iopub.status.idle":"2022-05-24T11:36:43.528844Z","shell.execute_reply.started":"2022-05-24T11:36:43.509729Z","shell.execute_reply":"2022-05-24T11:36:43.527756Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:45.823176Z","iopub.execute_input":"2022-05-24T11:36:45.823545Z","iopub.status.idle":"2022-05-24T11:36:45.828781Z","shell.execute_reply.started":"2022-05-24T11:36:45.823520Z","shell.execute_reply":"2022-05-24T11:36:45.827881Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# X we will keep all columns execpt the last one \nX_train_deep = np.expand_dims(dataset.values[:,:-1],axis = 2)\n# the last column is our label\ny_train_deep = dataset.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test_deep = np.expand_dims(dataset.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train_deep.shape,y_train_deep.shape,X_test_deep.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:48.470854Z","iopub.execute_input":"2022-05-24T11:36:48.471122Z","iopub.status.idle":"2022-05-24T11:36:48.478952Z","shell.execute_reply.started":"2022-05-24T11:36:48.471092Z","shell.execute_reply":"2022-05-24T11:36:48.478218Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"save_best = tf.keras.callbacks.ModelCheckpoint(\"Model.h5\", monitor='val_loss',verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:50.942752Z","iopub.execute_input":"2022-05-24T11:36:50.943569Z","iopub.status.idle":"2022-05-24T11:36:50.948864Z","shell.execute_reply.started":"2022-05-24T11:36:50.943541Z","shell.execute_reply":"2022-05-24T11:36:50.948021Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    \n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True), input_shape=(33, 1)))\n\n    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n    model.add(tf.keras.layers.Dropout(0.2))\n\n    model.add(tf.keras.layers.Flatten())\n    \n    model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer='uniform'))\n    model.add(tf.keras.layers.Dense(1))\n    \n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = 'mse', metrics=['mse'])\n\n    model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:53.545942Z","iopub.execute_input":"2022-05-24T11:36:53.547092Z","iopub.status.idle":"2022-05-24T11:36:53.553270Z","shell.execute_reply.started":"2022-05-24T11:36:53.547033Z","shell.execute_reply":"2022-05-24T11:36:53.552802Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:36:56.405969Z","iopub.execute_input":"2022-05-24T11:36:56.407057Z","iopub.status.idle":"2022-05-24T11:36:57.858078Z","shell.execute_reply.started":"2022-05-24T11:36:56.406976Z","shell.execute_reply":"2022-05-24T11:36:57.857028Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train_deep, y_train_deep, validation_split=0.2, epochs=40, batch_size=512, verbose=1, callbacks=[save_best])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:37:01.094116Z","iopub.execute_input":"2022-05-24T11:37:01.094354Z","iopub.status.idle":"2022-05-24T13:51:19.241975Z","shell.execute_reply.started":"2022-05-24T11:37:01.094331Z","shell.execute_reply":"2022-05-24T13:51:19.241373Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_train_deep, y_train_deep)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T13:51:19.243777Z","iopub.execute_input":"2022-05-24T13:51:19.245103Z","iopub.status.idle":"2022-05-24T13:54:58.210347Z","shell.execute_reply.started":"2022-05-24T13:51:19.245035Z","shell.execute_reply":"2022-05-24T13:54:58.209284Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('./Model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T13:54:58.211521Z","iopub.execute_input":"2022-05-24T13:54:58.211733Z","iopub.status.idle":"2022-05-24T13:54:58.943590Z","shell.execute_reply.started":"2022-05-24T13:54:58.211703Z","shell.execute_reply":"2022-05-24T13:54:58.942803Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# creating submission file \nsubmission = model.predict(X_test_deep, verbose=1)\n# we will keep every value between 0 and 20\nsubmission = submission.clip(0,20)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T13:54:58.944830Z","iopub.execute_input":"2022-05-24T13:54:58.944984Z","iopub.status.idle":"2022-05-24T13:58:29.337178Z","shell.execute_reply.started":"2022-05-24T13:54:58.944963Z","shell.execute_reply":"2022-05-24T13:58:29.336254Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test_df['ID'],'item_cnt_month':submission.ravel()})\n# creating csv file from dataframe\nsubmission.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":72,"outputs":[]}]}